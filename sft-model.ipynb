{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(32 * (height//2) * (width//2), 128)\n        self.fc2 = nn.Linear(128, 64)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = x.view(-1, 32 * (height//2) * (width//2))\n        x = torch.relu(self.fc1(x))\n        return torch.relu(self.fc2(x))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, cnn, lstm_hidden_size, num_layers, sequence_length):\n        super(LSTM, self).__init__()\n        self.cnn = cnn\n        self.lstm = nn.LSTM(input_size=64, hidden_size=lstm_hidden_size, num_layers=num_layers, batch_first=True)\n        self.fc_out = nn.Linear(lstm_hidden_size, 1)  # Output layer for image prediction\n\n    def forward(self, x):\n        batch_size, seq_len, channels, height, width = x.shape\n        cnn_out = []\n        \n        for t in range(seq_len):\n            frame = x[:, t, :, :, :]  # Get each frame in the sequence\n            cnn_out.append(self.cnn(frame))  # Extract spatial features using CNN\n        \n        cnn_out = torch.stack(cnn_out, dim=1)  # Stack CNN outputs for LSTM input\n        lstm_out, _ = self.lstm(cnn_out)  # Pass through LSTM\n        \n        # Predict the next image (or frame)\n        output = self.fc_out(lstm_out[:, -1, :])  # Use the last LSTM output for prediction\n        return output\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}